âœ… METODOLOGÃA PROPUESTA (GUÃA PASO A PASO)

Objetivo: entrenar un Transformer para predecir la clase 0â€“4 para cada vehÃ­culo (en su Ãºltimo readout), minimizar el costo total y preparar el archivo de predicciones.

ğŸ”µ FASE 1 â€” ENTENDER Y PREPARAR LOS DATOS (lo primero que harÃ¡s)
1.1 Cargar archivos grandes de lectura operacional

train_operational_readouts.csv

validation_operational_readouts.csv

test_operational_readouts.csv

Cada archivo tiene:

vehicle_id

time_step

~14 variables (algunas con bins)

ğŸ‘‰ Son secuencias multivariadas irregulares â†’ IDEAL para Transformers.

1.2 Cargar la informaciÃ³n complementaria

train_specifications.csv

validation_specifications.csv

test_specifications.csv

ğŸ‘‰ Uso: codificaciÃ³n categÃ³rica (embeddings).

1.3 Cargar los labels

train_tte.csv â†’ se usa solo para construir etiquetas 0â€“4

validation_labels.csv â†’ etiquetas ya listas

test â†’ no tiene labels

1.4 Construir la etiqueta (clase 0â€“4) para el train

SegÃºn las reglas:

Clase	Tiempo antes de falla
1	48â€“24
2	24â€“12
3	12â€“6
4	6â€“0
0	No fallÃ³

ğŸ‘‰ Procesamiento:
Para cada vehicle_id del training:

Tomar su length_of_study_time_step desde train_tte.csv

Recorrer sus readouts.

SegÃºn el tiempo relativo al evento â†’ asignar clase 0â€“4 al Ãºltimo readout.

Esto produce tu dataset final:

vehicle_id | sequence_of_readouts | specs | label

ğŸ”µ FASE 2 â€” CREAR EL DATASET FINAL LISTO PARA TRANSFORMERS
2.1 Agrupar por vehÃ­culo

Para cada vehÃ­culo:

ordenar por time_step

normalizar cada feature

secuencia = matriz [longitud variable x n_features]

Ejemplo:

VehÃ­culo 123  
[[0.21, 1, 0, ...],
 [0.23, 0, 1, ...],
 [0.19, 1, 0, ...], ...]

2.2 Cortar secuencias o aplicar padding

Transformers requieren un tamaÃ±o fijo â†’ recomiendo:

MAX_SEQ_LEN â‰ˆ 200â€“300

Padding + mÃ¡scara de atenciÃ³n

2.3 Procesar especificaciones

Usar embeddings tipo NLP:

engine_type â†’ embedding 16d  
wheel_config â†’ embedding 8d  


Y concatenar al embedding del CLS token.

ğŸ”µ FASE 3 â€” MODELADO (Transformers)

AquÃ­ empieza lo fuerte pero ya todo estÃ¡ organizado.

3.1 Arquitectura

Modelo recomendado:

[CLS] + embeddings de secuencia â†’ Transformer Encoder â†’ MLP â†’ clase 0â€“4


Componentes:

Embedding denso para features numÃ©ricos

Positional encoding aprendible

2â€“3 capas Transformer Encoder

Dropout bajo (0.1)

Capa final de clasificaciÃ³n con 5 logits

3.2 FunciÃ³n de pÃ©rdida

Este challenge usa COSTOS â†’ NO accuracy.

Debes usar Cost-sensitive loss:

loss = cross_entropy * weight[label][pred]


O usar matriz de costo directamente.

Esto es la â€œgraciaâ€ del challenge:
ğŸ‘‰ No gana quien tiene mejor accuracy, sino quien minimiza el costo.

3.3 Entrenamiento

batch size = 16â€“32 (dependiendo de GPU)

10â€“20 epochs

early stopping por costo validaciÃ³n

optimizador AdamW

ğŸ”µ FASE 4 â€” VALIDACIÃ“N

Usa:

Secuencias truncadas de validaciÃ³n

Labels de validation_labels.csv

EvalÃºa:

matriz de confusiÃ³n

Total_cost usando la matriz del challenge

Si el costo es muy alto, ajustar:

class weights

nÃºmero de capas

embeddings

tamaÃ±o secuencia

ğŸ”µ FASE 5 â€” GENERAR PREDICCIONES DEL TEST

El archivo de salida debe tener:

vehicle_id, predicted_class


Pasos:

Cargar secuencias completas del test.

Tomar solo el Ãºltimo readout por vehÃ­culo (ya estÃ¡ asÃ­ el dataset).

Preprocesar igual que train/val.

Pasar por el modelo.

Generar clase 0â€“4.

Exportar como IDA_Industrial_challenge_2024_predictions.csv.

ğŸ”µ FASE 6 â€” RESULTADOS

Tu paper debe mostrar:

GrÃ¡ficos de distribuciÃ³n de clases

Arquitectura del Transformer

Tabla comparativa: LSTM vs Transformer

Matriz de costos obtenida

Ablation de hiperparÃ¡metros

JustificaciÃ³n:
â€œLos Transformers capturan dependencias globales entre sensores multivariados de forma efectivaâ€.

ğŸ”µ FASE 7 â€” ENTREGA FINAL

Enviar:

IDA_Industrial_challenge_2024_predictions.csv

Paper en formato de la conferencia

âœ… RESUMEN SUPER CORTO PARA TI (tu checklist real):
Paso 1 â€” Preparar etiquetas del train

Usar train_tte + reglas 48â€“0.

Paso 2 â€” Construir secuencias por vehÃ­culo

Agrupar, ordenar, pad, normalizar.

Paso 3 â€” Embeddings para especificaciones
Paso 4 â€” Entrenar Transformer + cost-sensitive loss
Paso 5 â€” Validar usando validation_labels
Paso 6 â€” Predecir test
Paso 7 â€” Generar CSV
